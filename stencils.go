// Copyright 2020-2025 Buf Technologies, Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package fastpb

import (
	"github.com/bufbuild/fastpb/internal/arena"
	"github.com/bufbuild/fastpb/internal/dbg"
	"github.com/bufbuild/fastpb/internal/swiss"
	"github.com/bufbuild/fastpb/internal/unsafe2"
	"google.golang.org/protobuf/encoding/protowire"
	"math/bits"
)

// Code generated by internal/stencil. DO NOT EDIT

func parseScalarMapV32xV32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[varintItem[uint32], varintItem[uint32], uint32, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki varintItem[uint32]
	var vi varintItem[uint32]
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapV32xV64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[varintItem[uint32], varintItem[uint64], uint32, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki varintItem[uint32]
	var vi varintItem[uint64]
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapV32xZ32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[varintItem[uint32], zigzagItem[uint32], uint32, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki varintItem[uint32]
	var vi zigzagItem[uint32]
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapV32xZ64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[varintItem[uint32], zigzagItem[uint64], uint32, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki varintItem[uint32]
	var vi zigzagItem[uint64]
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapV32xF32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[varintItem[uint32], fixed32Item, uint32, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki varintItem[uint32]
	var vi fixed32Item
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapV32xF64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[varintItem[uint32], fixed64Item, uint32, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki varintItem[uint32]
	var vi fixed64Item
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapV32xV1(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[varintItem[uint32], boolItem, uint32, uint8]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki varintItem[uint32]
	var vi boolItem
	var k uint32
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint8]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint8]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint8](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint8]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU8(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint8](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint8]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU8(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU8(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapV32xS(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[varintItem[uint32], stringItem, uint32, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki varintItem[uint32]
	var vi stringItem
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapV32xB(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[varintItem[uint32], bytesItem, uint32, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki varintItem[uint32]
	var vi bytesItem
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapV64xV32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[varintItem[uint64], varintItem[uint32], uint64, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki varintItem[uint64]
	var vi varintItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapV64xV64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[varintItem[uint64], varintItem[uint64], uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki varintItem[uint64]
	var vi varintItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapV64xZ32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[varintItem[uint64], zigzagItem[uint32], uint64, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki varintItem[uint64]
	var vi zigzagItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapV64xZ64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[varintItem[uint64], zigzagItem[uint64], uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki varintItem[uint64]
	var vi zigzagItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapV64xF32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[varintItem[uint64], fixed32Item, uint64, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki varintItem[uint64]
	var vi fixed32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapV64xF64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[varintItem[uint64], fixed64Item, uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki varintItem[uint64]
	var vi fixed64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapV64xV1(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[varintItem[uint64], boolItem, uint64, uint8]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki varintItem[uint64]
	var vi boolItem
	var k uint64
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint8]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint8]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint8](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint8]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU8(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint8](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint8]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU8(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU8(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapV64xS(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[varintItem[uint64], stringItem, uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki varintItem[uint64]
	var vi stringItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapV64xB(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[varintItem[uint64], bytesItem, uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki varintItem[uint64]
	var vi bytesItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapZ32xV32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[zigzagItem[uint32], varintItem[uint32], uint32, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki zigzagItem[uint32]
	var vi varintItem[uint32]
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapZ32xV64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[zigzagItem[uint32], varintItem[uint64], uint32, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki zigzagItem[uint32]
	var vi varintItem[uint64]
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapZ32xZ32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[zigzagItem[uint32], zigzagItem[uint32], uint32, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki zigzagItem[uint32]
	var vi zigzagItem[uint32]
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapZ32xZ64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[zigzagItem[uint32], zigzagItem[uint64], uint32, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki zigzagItem[uint32]
	var vi zigzagItem[uint64]
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapZ32xF32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[zigzagItem[uint32], fixed32Item, uint32, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki zigzagItem[uint32]
	var vi fixed32Item
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapZ32xF64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[zigzagItem[uint32], fixed64Item, uint32, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki zigzagItem[uint32]
	var vi fixed64Item
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapZ32xV1(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[zigzagItem[uint32], boolItem, uint32, uint8]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki zigzagItem[uint32]
	var vi boolItem
	var k uint32
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint8]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint8]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint8](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint8]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU8(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint8](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint8]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU8(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU8(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapZ32xS(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[zigzagItem[uint32], stringItem, uint32, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki zigzagItem[uint32]
	var vi stringItem
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapZ32xB(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[zigzagItem[uint32], bytesItem, uint32, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki zigzagItem[uint32]
	var vi bytesItem
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapZ64xV32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[zigzagItem[uint64], varintItem[uint32], uint64, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki zigzagItem[uint64]
	var vi varintItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapZ64xV64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[zigzagItem[uint64], varintItem[uint64], uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki zigzagItem[uint64]
	var vi varintItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapZ64xZ32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[zigzagItem[uint64], zigzagItem[uint32], uint64, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki zigzagItem[uint64]
	var vi zigzagItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapZ64xZ64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[zigzagItem[uint64], zigzagItem[uint64], uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki zigzagItem[uint64]
	var vi zigzagItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapZ64xF32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[zigzagItem[uint64], fixed32Item, uint64, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki zigzagItem[uint64]
	var vi fixed32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapZ64xF64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[zigzagItem[uint64], fixed64Item, uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki zigzagItem[uint64]
	var vi fixed64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapZ64xV1(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[zigzagItem[uint64], boolItem, uint64, uint8]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki zigzagItem[uint64]
	var vi boolItem
	var k uint64
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint8]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint8]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint8](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint8]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU8(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint8](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint8]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU8(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU8(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapZ64xS(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[zigzagItem[uint64], stringItem, uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki zigzagItem[uint64]
	var vi stringItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapZ64xB(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[zigzagItem[uint64], bytesItem, uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki zigzagItem[uint64]
	var vi bytesItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapF32xV32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[fixed32Item, varintItem[uint32], uint32, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki fixed32Item
	var vi varintItem[uint32]
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapF32xV64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[fixed32Item, varintItem[uint64], uint32, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki fixed32Item
	var vi varintItem[uint64]
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapF32xZ32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[fixed32Item, zigzagItem[uint32], uint32, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki fixed32Item
	var vi zigzagItem[uint32]
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapF32xZ64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[fixed32Item, zigzagItem[uint64], uint32, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki fixed32Item
	var vi zigzagItem[uint64]
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapF32xF32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[fixed32Item, fixed32Item, uint32, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki fixed32Item
	var vi fixed32Item
	var k uint32
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapF32xF64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[fixed32Item, fixed64Item, uint32, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki fixed32Item
	var vi fixed64Item
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapF32xV1(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[fixed32Item, boolItem, uint32, uint8]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki fixed32Item
	var vi boolItem
	var k uint32
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint8]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint8]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint8](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint8]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU8(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint8](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint8]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU8(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU8(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapF32xS(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[fixed32Item, stringItem, uint32, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki fixed32Item
	var vi stringItem
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapF32xB(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[fixed32Item, bytesItem, uint32, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki fixed32Item
	var vi bytesItem
	var k uint32
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint32, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint32, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint32, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU32xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU32xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint32, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint32, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU32xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU32xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapF64xV32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[fixed64Item, varintItem[uint32], uint64, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki fixed64Item
	var vi varintItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapF64xV64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[fixed64Item, varintItem[uint64], uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki fixed64Item
	var vi varintItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapF64xZ32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[fixed64Item, zigzagItem[uint32], uint64, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki fixed64Item
	var vi zigzagItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapF64xZ64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[fixed64Item, zigzagItem[uint64], uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki fixed64Item
	var vi zigzagItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapF64xF32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[fixed64Item, fixed32Item, uint64, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki fixed64Item
	var vi fixed32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapF64xF64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[fixed64Item, fixed64Item, uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki fixed64Item
	var vi fixed64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapF64xV1(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[fixed64Item, boolItem, uint64, uint8]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki fixed64Item
	var vi boolItem
	var k uint64
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint8]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint8]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint8](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint8]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU8(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint8](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint8]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU8(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU8(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapF64xS(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[fixed64Item, stringItem, uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki fixed64Item
	var vi stringItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapF64xB(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[fixed64Item, bytesItem, uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki fixed64Item
	var vi bytesItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapSxV32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[stringItem, varintItem[uint32], uint64, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki stringItem
	var vi varintItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapSxV64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[stringItem, varintItem[uint64], uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki stringItem
	var vi varintItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapSxZ32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[stringItem, zigzagItem[uint32], uint64, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki stringItem
	var vi zigzagItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapSxZ64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[stringItem, zigzagItem[uint64], uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki stringItem
	var vi zigzagItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapSxF32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[stringItem, fixed32Item, uint64, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki stringItem
	var vi fixed32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapSxF64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[stringItem, fixed64Item, uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki stringItem
	var vi fixed64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapSxV1(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[stringItem, boolItem, uint64, uint8]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki stringItem
	var vi boolItem
	var k uint64
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint8]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint8]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint8](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint8]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU8(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint8](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint8]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU8(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU8(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapSxS(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[stringItem, stringItem, uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki stringItem
	var vi stringItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapSxB(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[stringItem, bytesItem, uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki stringItem
	var vi bytesItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapBxV32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[bytesItem, varintItem[uint32], uint64, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki bytesItem
	var vi varintItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapBxV64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[bytesItem, varintItem[uint64], uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki bytesItem
	var vi varintItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapBxZ32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[bytesItem, zigzagItem[uint32], uint64, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki bytesItem
	var vi zigzagItem[uint32]
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapBxZ64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[bytesItem, zigzagItem[uint64], uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki bytesItem
	var vi zigzagItem[uint64]
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapBxF32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[bytesItem, fixed32Item, uint64, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki bytesItem
	var vi fixed32Item
	var k uint64
	var v uint32

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint32]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint32]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint32](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU32(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU32(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint32](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint32]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU32(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU32(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapBxF64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[bytesItem, fixed64Item, uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki bytesItem
	var vi fixed64Item
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapBxV1(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[bytesItem, boolItem, uint64, uint8]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki bytesItem
	var vi boolItem
	var k uint64
	var v uint8

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint8]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint8]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint8](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint8]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU8(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU8(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint8](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint8]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU8(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU8(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapBxS(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[bytesItem, stringItem, uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki bytesItem
	var vi stringItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseScalarMapBxB(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseScalarMap[bytesItem, bytesItem, uint64, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var ki bytesItem
	var vi bytesItem
	var k uint64
	var v uint64

	kTag := protowire.EncodeTag(1, ki.kind())
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		p1, p2, k = ki.parse(p1, p2)
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			p1, p2, k = ki.parse(p1, p2)
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	extract := ki.extract(p1, p2)
	var mp **swiss.Table[uint64, uint64]
	p1, p2, mp = getMutableField[*swiss.Table[uint64, uint64]](p1, p2)

	m := *mp
	if m == nil {
		size, _ := swiss.Layout[uint64, uint64](1)
		m = unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m)
		swiss.InitU64xU64(m, 1, nil, extract)
	}

	vp := swiss.InsertU64xU64(m, k, extract)
	if vp == nil {
		size, _ := swiss.Layout[uint64, uint64](m.Len() + 1)
		m2 := unsafe2.Cast[swiss.Table[uint64, uint64]](p1.arena().Alloc(size))
		unsafe2.StoreNoWB(mp, m2)
		swiss.InitU64xU64(m2, m.Len()+1, m, extract)
		vp = swiss.InsertU64xU64(m2, k, extract)
	}

	*vp = v

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseBoolScalarMapV32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseBoolScalarMap[varintItem[uint32], uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var p *uint32
	p1, p2, p = getMutableField[uint32](p1, p2)

	var k bool
	var vi varintItem[uint32]
	var v uint32

	kTag := protowire.EncodeTag(1, protowire.VarintType)
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		var n uint64
		p1, p2, n = p1.varint(p2)
		k = n != 0
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			var n uint64
			p1, p2, n = p1.varint(p2)
			k = n != 0
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	var idx uint32
	if k {
		idx = 1
	}

	*unsafe2.Add(p, idx) = v
	p2.m().setBit(p2.f().offset.bit+idx, true)

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseBoolScalarMapV64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseBoolScalarMap[varintItem[uint64], uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var p *uint64
	p1, p2, p = getMutableField[uint64](p1, p2)

	var k bool
	var vi varintItem[uint64]
	var v uint64

	kTag := protowire.EncodeTag(1, protowire.VarintType)
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		var n uint64
		p1, p2, n = p1.varint(p2)
		k = n != 0
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			var n uint64
			p1, p2, n = p1.varint(p2)
			k = n != 0
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	var idx uint32
	if k {
		idx = 1
	}

	*unsafe2.Add(p, idx) = v
	p2.m().setBit(p2.f().offset.bit+idx, true)

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseBoolScalarMapZ32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseBoolScalarMap[zigzagItem[uint32], uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var p *uint32
	p1, p2, p = getMutableField[uint32](p1, p2)

	var k bool
	var vi zigzagItem[uint32]
	var v uint32

	kTag := protowire.EncodeTag(1, protowire.VarintType)
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		var n uint64
		p1, p2, n = p1.varint(p2)
		k = n != 0
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			var n uint64
			p1, p2, n = p1.varint(p2)
			k = n != 0
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	var idx uint32
	if k {
		idx = 1
	}

	*unsafe2.Add(p, idx) = v
	p2.m().setBit(p2.f().offset.bit+idx, true)

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseBoolScalarMapZ64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseBoolScalarMap[zigzagItem[uint64], uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var p *uint64
	p1, p2, p = getMutableField[uint64](p1, p2)

	var k bool
	var vi zigzagItem[uint64]
	var v uint64

	kTag := protowire.EncodeTag(1, protowire.VarintType)
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		var n uint64
		p1, p2, n = p1.varint(p2)
		k = n != 0
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			var n uint64
			p1, p2, n = p1.varint(p2)
			k = n != 0
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	var idx uint32
	if k {
		idx = 1
	}

	*unsafe2.Add(p, idx) = v
	p2.m().setBit(p2.f().offset.bit+idx, true)

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseBoolScalarMapF32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseBoolScalarMap[fixed32Item, uint32]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var p *uint32
	p1, p2, p = getMutableField[uint32](p1, p2)

	var k bool
	var vi fixed32Item
	var v uint32

	kTag := protowire.EncodeTag(1, protowire.VarintType)
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		var n uint64
		p1, p2, n = p1.varint(p2)
		k = n != 0
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			var n uint64
			p1, p2, n = p1.varint(p2)
			k = n != 0
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	var idx uint32
	if k {
		idx = 1
	}

	*unsafe2.Add(p, idx) = v
	p2.m().setBit(p2.f().offset.bit+idx, true)

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseBoolScalarMapF64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseBoolScalarMap[fixed64Item, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var p *uint64
	p1, p2, p = getMutableField[uint64](p1, p2)

	var k bool
	var vi fixed64Item
	var v uint64

	kTag := protowire.EncodeTag(1, protowire.VarintType)
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		var n uint64
		p1, p2, n = p1.varint(p2)
		k = n != 0
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			var n uint64
			p1, p2, n = p1.varint(p2)
			k = n != 0
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	var idx uint32
	if k {
		idx = 1
	}

	*unsafe2.Add(p, idx) = v
	p2.m().setBit(p2.f().offset.bit+idx, true)

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseBoolScalarMapS(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseBoolScalarMap[stringItem, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var p *uint64
	p1, p2, p = getMutableField[uint64](p1, p2)

	var k bool
	var vi stringItem
	var v uint64

	kTag := protowire.EncodeTag(1, protowire.VarintType)
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		var n uint64
		p1, p2, n = p1.varint(p2)
		k = n != 0
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			var n uint64
			p1, p2, n = p1.varint(p2)
			k = n != 0
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	var idx uint32
	if k {
		idx = 1
	}

	*unsafe2.Add(p, idx) = v
	p2.m().setBit(p2.f().offset.bit+idx, true)

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}
func parseBoolScalarMapB(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseBoolScalarMap[bytesItem, uint64]

	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	var p *uint64
	p1, p2, p = getMutableField[uint64](p1, p2)

	var k bool
	var vi bytesItem
	var v uint64

	kTag := protowire.EncodeTag(1, protowire.VarintType)
	vTag := protowire.EncodeTag(2, vi.kind())

	if p1.len() == 0 {
		goto insert
	}
	p1.log(p2, "first byte", "%#02x", *p1.b())
	if *p1.b() == byte(kTag) {
		p1.b_++
		var n uint64
		p1, p2, n = p1.varint(p2)
		k = n != 0
		if p1.len() == 0 {
			goto insert
		}
		p1.log(p2, "second byte", "%#02x", *p1.b())
		if *p1.b() == byte(vTag) {
			p1.b_++
			p1, p2, v = vi.parse(p1, p2)
			p1.log(p2, "map done?",
				"%v:%v, %v/%x: %v/%x",
				p1.b_, p1.e_,
				k, unsafe2.Bytes(&k),
				v, unsafe2.Bytes(&v))
			if p1.b_ == p1.e_ {
				goto insert
			}
		}
	}

	for p1.b_ < p1.e_ {
		var tag uint64
		p1, p2, tag = p1.varint(p2)
		switch tag {
		case kTag:
			var n uint64
			p1, p2, n = p1.varint(p2)
			k = n != 0
		case vTag:
			p1, p2, v = vi.parse(p1, p2)
		default:
			n, t := protowire.DecodeTag(tag)
			m := protowire.ConsumeFieldValue(n, t, p1.buf())
			if m < 0 {
				p1.fail(p2, -errCode(m))
			}
			p1.b_ = p1.b_.Add(m)
		}
	}

insert:
	var idx uint32
	if k {
		idx = 1
	}

	*unsafe2.Add(p, idx) = v
	p2.m().setBit(p2.f().offset.bit+idx, true)

	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}

//go:nosplit
func parseOneofVarint32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseOneofVarint[uint32]
	p1, p2, p2.scratch = p1.varint(p2)
	p1, p2 = storeFromScratch[uint32](p1, p2)
	unsafe2.ByteStore(p2.m(), p2.f().offset.bit, p2.f().offset.number)

	return p1, p2
}

//go:nosplit
func parseOneofVarint64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseOneofVarint[uint64]
	p1, p2, p2.scratch = p1.varint(p2)
	p1, p2 = storeFromScratch[uint64](p1, p2)
	unsafe2.ByteStore(p2.m(), p2.f().offset.bit, p2.f().offset.number)

	return p1, p2
}

//go:nosplit
func parseOneofZigZag32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseOneofZigZag[uint32]
	p1, p2, p2.scratch = p1.varint(p2)
	p2.scratch = uint64(zigzag64[uint32](p2.scratch))
	p1, p2 = storeFromScratch[uint32](p1, p2)
	unsafe2.ByteStore(p2.m(), p2.f().offset.bit, p2.f().offset.number)

	return p1, p2
}

//go:nosplit
func parseOneofZigZag64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseOneofZigZag[uint64]
	p1, p2, p2.scratch = p1.varint(p2)
	p2.scratch = uint64(zigzag64[uint64](p2.scratch))
	p1, p2 = storeFromScratch[uint64](p1, p2)
	unsafe2.ByteStore(p2.m(), p2.f().offset.bit, p2.f().offset.number)

	return p1, p2
}

//go:nosplit
func parseOptionalVarint32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseOptionalVarint[uint32]
	p1, p2, p2.scratch = p1.varint(p2)
	p1, p2 = storeFromScratch[uint32](p1, p2)
	p1, p2 = p1.setBit(p2)

	return p1, p2
}

//go:nosplit
func parseOptionalVarint64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseOptionalVarint[uint64]
	p1, p2, p2.scratch = p1.varint(p2)
	p1, p2 = storeFromScratch[uint64](p1, p2)
	p1, p2 = p1.setBit(p2)

	return p1, p2
}

//go:nosplit
func parseOptionalZigZag32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseOptionalZigZag[uint32]
	p1, p2, p2.scratch = p1.varint(p2)
	p2.scratch = uint64(zigzag64[uint32](p2.scratch))
	p1, p2 = storeFromScratch[uint32](p1, p2)
	p1, p2 = p1.setBit(p2)

	return p1, p2
}

//go:nosplit
func parseOptionalZigZag64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseOptionalZigZag[uint64]
	p1, p2, p2.scratch = p1.varint(p2)
	p2.scratch = uint64(zigzag64[uint64](p2.scratch))
	p1, p2 = storeFromScratch[uint64](p1, p2)
	p1, p2 = p1.setBit(p2)

	return p1, p2
}

//go:nosplit
func spillArena32(p1 parser1, p2 parser2, rep arena.Slice[uint32]) (parser1, parser2, arena.Slice[uint32]) {
	_ = spillArena[uint32]
	return p1, p2, arena.SliceOf(p1.arena(), unwrapZC(rep, p1.c().src)...)
}

//go:nosplit
func spillArena64(p1 parser1, p2 parser2, rep arena.Slice[uint64]) (parser1, parser2, arena.Slice[uint64]) {
	_ = spillArena[uint64]
	return p1, p2, arena.SliceOf(p1.arena(), unwrapZC(rep, p1.c().src)...)
}

//go:nosplit
func parseRepeatedVarint8(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseRepeatedVarint[uint8]
	var n uint64
	p1, p2, n = p1.varint(p2)

	var slot *arena.SliceAddr[uint8]
	p1, p2, slot = getMutableField[arena.SliceAddr[uint8]](p1, p2)
	slice := slot.AssertValid()

	if isZC(slice) && slice.Cap() > 0 {

		zc := unwrapRawZC(slice).bytes(p1.c().src)
		slice := arena.NewSlice[uint8](p1.arena(), len(zc)+1)
		for i, b := range zc {
			slice.Store(i, uint8(b))
		}
		slice.Store(slice.Len()-1, uint8(n))
		p1.log(p2, "spill", "%v %v", slice.Addr(), slice)

		*slot = slice.Addr()
		return p1, p2
	}

	if slice.Len() < slice.Cap() {
		slice = slice.SetLen(slice.Len() + 1)
		slice.Store(slice.Len()-1, uint8(n))

		p1.log(p2, "store", "%v %v", slice.Addr(), slice)
		*slot = slice.Addr()
		return p1, p2
	}

	slice = slice.AppendOne(p1.arena(), uint8(n))
	p1.log(p2, "append", "%v %v", slice.Addr(), slice)
	*slot = slice.Addr()
	return p1, p2
}

//go:nosplit
func parseRepeatedVarint32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseRepeatedVarint[uint32]
	var n uint64
	p1, p2, n = p1.varint(p2)

	var slot *arena.SliceAddr[uint32]
	p1, p2, slot = getMutableField[arena.SliceAddr[uint32]](p1, p2)
	slice := slot.AssertValid()

	if isZC(slice) && slice.Cap() > 0 {

		zc := unwrapRawZC(slice).bytes(p1.c().src)
		slice := arena.NewSlice[uint32](p1.arena(), len(zc)+1)
		for i, b := range zc {
			slice.Store(i, uint32(b))
		}
		slice.Store(slice.Len()-1, uint32(n))
		p1.log(p2, "spill", "%v %v", slice.Addr(), slice)

		*slot = slice.Addr()
		return p1, p2
	}

	if slice.Len() < slice.Cap() {
		slice = slice.SetLen(slice.Len() + 1)
		slice.Store(slice.Len()-1, uint32(n))

		p1.log(p2, "store", "%v %v", slice.Addr(), slice)
		*slot = slice.Addr()
		return p1, p2
	}

	slice = slice.AppendOne(p1.arena(), uint32(n))
	p1.log(p2, "append", "%v %v", slice.Addr(), slice)
	*slot = slice.Addr()
	return p1, p2
}

//go:nosplit
func parseRepeatedVarint64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseRepeatedVarint[uint64]
	var n uint64
	p1, p2, n = p1.varint(p2)

	var slot *arena.SliceAddr[uint64]
	p1, p2, slot = getMutableField[arena.SliceAddr[uint64]](p1, p2)
	slice := slot.AssertValid()

	if isZC(slice) && slice.Cap() > 0 {

		zc := unwrapRawZC(slice).bytes(p1.c().src)
		slice := arena.NewSlice[uint64](p1.arena(), len(zc)+1)
		for i, b := range zc {
			slice.Store(i, uint64(b))
		}
		slice.Store(slice.Len()-1, uint64(n))
		p1.log(p2, "spill", "%v %v", slice.Addr(), slice)

		*slot = slice.Addr()
		return p1, p2
	}

	if slice.Len() < slice.Cap() {
		slice = slice.SetLen(slice.Len() + 1)
		slice.Store(slice.Len()-1, uint64(n))

		p1.log(p2, "store", "%v %v", slice.Addr(), slice)
		*slot = slice.Addr()
		return p1, p2
	}

	slice = slice.AppendOne(p1.arena(), uint64(n))
	p1.log(p2, "append", "%v %v", slice.Addr(), slice)
	*slot = slice.Addr()
	return p1, p2
}

//go:nosplit
func parsePackedVarint8(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parsePackedVarint[uint8]
	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)
	if n == 0 {
		return p1, p2
	}

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	// Count the number of varints in this packed field. We do this by counting
	// bytes without the sign bit set, in groups of 8.
	var count int
	for p := p1.b_; p < p1.e_; p += 8 {
		n := min(8, p1.e_-p)
		bytes := *unsafe2.Cast[uint64](p.AssertValid())
		bytes |= signBits << (n * 8)
		count += bits.OnesCount64(signBits &^ bytes)
	}

	var slot *arena.SliceAddr[uint8]
	p1, p2, slot = getMutableField[arena.SliceAddr[uint8]](p1, p2)
	slice := slot.AssertValid()
	if isZC(slice) {

		switch {
		case slice.Cap() > 0:

			zc := unwrapRawZC(slice).bytes(p1.c().src)
			slice = arena.NewSlice[uint8](p1.arena(), len(zc)+count)
			for i, b := range zc {
				slice.Store(i, uint8(b))
			}
			slice = slice.SetLen(len(zc))

			p1.log(p2, "spill", "%v %v", slice.Addr(), slice)

		case count == int(n):
			*slot = wrapZC[uint8](newZC(p1.c().src, p1.b(), int(n))).Addr()

			if dbg.Enabled {
				raw := unwrapRawZC(slot.AssertValid()).bytes(p1.c().src)
				p1.log(p2, "zc", "%v %v", *slot, raw)
			}

			p1.b_ = p1.e_
			p1.e_ = unsafe2.Addr[byte](p2.scratch)
			return p1, p2

		default:
			slice = slice.Grow(p1.arena(), count)
			p1.log(p2, "grow", "%v %v", slice.Addr(), slice)
		}
	} else if spare := slice.Cap() - slice.Len(); spare < count {
		slice = slice.Grow(p1.arena(), count-spare)
		p1.log(p2, "grow", "%v %v, %d", slice.Addr(), slice, spare)
	}

	p := unsafe2.AddrOf(slice.Ptr()).Add(slice.Len())

	switch {
	case count == p1.len():
		for {
			*p.AssertValid() = uint8(*p1.b())
			p1.b_++
			p = p.Add(1)

			if p1.b_ != p1.e_ {
				continue
			}

			break
		}
	case count >= p1.len()/2:
		for {
			var x uint64
			if v := *p1.b(); int8(v) >= 0 {
				x = uint64(v)
				p1.b_++
			} else if c := p1.b_.Add(1); c != p1.e_ && int8(*c.AssertValid()) >= 0 {
				x = uint64(*p1.b()&0x7f) | uint64(*c.AssertValid())<<7
				p1.b_ += 2
			} else {
				p1, p2, x = p1.varint(p2)
			}

			*p.AssertValid() = uint8(x)
			p = p.Add(1)
			if p1.b_ != p1.e_ {
				continue
			}

			break
		}
	default:
		for {
			var x uint64
			p1, p2, x = p1.varint(p2)

			*p.AssertValid() = uint8(x)
			p = p.Add(1)
			if p1.b_ != p1.e_ {
				continue
			}

			break
		}
	}

	slice = slice.SetLen(p.Sub(unsafe2.AddrOf(slice.Ptr())))
	p1.log(p2, "append", "%v %v", slice.Addr(), slice)

	*slot = slice.Addr()
	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}

//go:nosplit
func parsePackedVarint32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parsePackedVarint[uint32]
	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)
	if n == 0 {
		return p1, p2
	}

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	// Count the number of varints in this packed field. We do this by counting
	// bytes without the sign bit set, in groups of 8.
	var count int
	for p := p1.b_; p < p1.e_; p += 8 {
		n := min(8, p1.e_-p)
		bytes := *unsafe2.Cast[uint64](p.AssertValid())
		bytes |= signBits << (n * 8)
		count += bits.OnesCount64(signBits &^ bytes)
	}

	var slot *arena.SliceAddr[uint32]
	p1, p2, slot = getMutableField[arena.SliceAddr[uint32]](p1, p2)
	slice := slot.AssertValid()
	if isZC(slice) {

		switch {
		case slice.Cap() > 0:

			zc := unwrapRawZC(slice).bytes(p1.c().src)
			slice = arena.NewSlice[uint32](p1.arena(), len(zc)+count)
			for i, b := range zc {
				slice.Store(i, uint32(b))
			}
			slice = slice.SetLen(len(zc))

			p1.log(p2, "spill", "%v %v", slice.Addr(), slice)

		case count == int(n):
			*slot = wrapZC[uint32](newZC(p1.c().src, p1.b(), int(n))).Addr()

			if dbg.Enabled {
				raw := unwrapRawZC(slot.AssertValid()).bytes(p1.c().src)
				p1.log(p2, "zc", "%v %v", *slot, raw)
			}

			p1.b_ = p1.e_
			p1.e_ = unsafe2.Addr[byte](p2.scratch)
			return p1, p2

		default:
			slice = slice.Grow(p1.arena(), count)
			p1.log(p2, "grow", "%v %v", slice.Addr(), slice)
		}
	} else if spare := slice.Cap() - slice.Len(); spare < count {
		slice = slice.Grow(p1.arena(), count-spare)
		p1.log(p2, "grow", "%v %v, %d", slice.Addr(), slice, spare)
	}

	p := unsafe2.AddrOf(slice.Ptr()).Add(slice.Len())

	switch {
	case count == p1.len():
		for {
			*p.AssertValid() = uint32(*p1.b())
			p1.b_++
			p = p.Add(1)

			if p1.b_ != p1.e_ {
				continue
			}

			break
		}
	case count >= p1.len()/2:
		for {
			var x uint64
			if v := *p1.b(); int8(v) >= 0 {
				x = uint64(v)
				p1.b_++
			} else if c := p1.b_.Add(1); c != p1.e_ && int8(*c.AssertValid()) >= 0 {
				x = uint64(*p1.b()&0x7f) | uint64(*c.AssertValid())<<7
				p1.b_ += 2
			} else {
				p1, p2, x = p1.varint(p2)
			}

			*p.AssertValid() = uint32(x)
			p = p.Add(1)
			if p1.b_ != p1.e_ {
				continue
			}

			break
		}
	default:
		for {
			var x uint64
			p1, p2, x = p1.varint(p2)

			*p.AssertValid() = uint32(x)
			p = p.Add(1)
			if p1.b_ != p1.e_ {
				continue
			}

			break
		}
	}

	slice = slice.SetLen(p.Sub(unsafe2.AddrOf(slice.Ptr())))
	p1.log(p2, "append", "%v %v", slice.Addr(), slice)

	*slot = slice.Addr()
	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}

//go:nosplit
func parsePackedVarint64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parsePackedVarint[uint64]
	var n uint32
	p1, p2, n = p1.lengthPrefix(p2)
	if n == 0 {
		return p1, p2
	}

	p2.scratch = uint64(p1.e_)
	p1.e_ = p1.b_.Add(int(n))

	// Count the number of varints in this packed field. We do this by counting
	// bytes without the sign bit set, in groups of 8.
	var count int
	for p := p1.b_; p < p1.e_; p += 8 {
		n := min(8, p1.e_-p)
		bytes := *unsafe2.Cast[uint64](p.AssertValid())
		bytes |= signBits << (n * 8)
		count += bits.OnesCount64(signBits &^ bytes)
	}

	var slot *arena.SliceAddr[uint64]
	p1, p2, slot = getMutableField[arena.SliceAddr[uint64]](p1, p2)
	slice := slot.AssertValid()
	if isZC(slice) {

		switch {
		case slice.Cap() > 0:

			zc := unwrapRawZC(slice).bytes(p1.c().src)
			slice = arena.NewSlice[uint64](p1.arena(), len(zc)+count)
			for i, b := range zc {
				slice.Store(i, uint64(b))
			}
			slice = slice.SetLen(len(zc))

			p1.log(p2, "spill", "%v %v", slice.Addr(), slice)

		case count == int(n):
			*slot = wrapZC[uint64](newZC(p1.c().src, p1.b(), int(n))).Addr()

			if dbg.Enabled {
				raw := unwrapRawZC(slot.AssertValid()).bytes(p1.c().src)
				p1.log(p2, "zc", "%v %v", *slot, raw)
			}

			p1.b_ = p1.e_
			p1.e_ = unsafe2.Addr[byte](p2.scratch)
			return p1, p2

		default:
			slice = slice.Grow(p1.arena(), count)
			p1.log(p2, "grow", "%v %v", slice.Addr(), slice)
		}
	} else if spare := slice.Cap() - slice.Len(); spare < count {
		slice = slice.Grow(p1.arena(), count-spare)
		p1.log(p2, "grow", "%v %v, %d", slice.Addr(), slice, spare)
	}

	p := unsafe2.AddrOf(slice.Ptr()).Add(slice.Len())

	switch {
	case count == p1.len():
		for {
			*p.AssertValid() = uint64(*p1.b())
			p1.b_++
			p = p.Add(1)

			if p1.b_ != p1.e_ {
				continue
			}

			break
		}
	case count >= p1.len()/2:
		for {
			var x uint64
			if v := *p1.b(); int8(v) >= 0 {
				x = uint64(v)
				p1.b_++
			} else if c := p1.b_.Add(1); c != p1.e_ && int8(*c.AssertValid()) >= 0 {
				x = uint64(*p1.b()&0x7f) | uint64(*c.AssertValid())<<7
				p1.b_ += 2
			} else {
				p1, p2, x = p1.varint(p2)
			}

			*p.AssertValid() = uint64(x)
			p = p.Add(1)
			if p1.b_ != p1.e_ {
				continue
			}

			break
		}
	default:
		for {
			var x uint64
			p1, p2, x = p1.varint(p2)

			*p.AssertValid() = uint64(x)
			p = p.Add(1)
			if p1.b_ != p1.e_ {
				continue
			}

			break
		}
	}

	slice = slice.SetLen(p.Sub(unsafe2.AddrOf(slice.Ptr())))
	p1.log(p2, "append", "%v %v", slice.Addr(), slice)

	*slot = slice.Addr()
	p1.e_ = unsafe2.Addr[byte](p2.scratch)
	return p1, p2
}

//go:nosplit
func appendFixed32(p1 parser1, p2 parser2, v uint32) (parser1, parser2) {
	_ = appendFixed[uint32]
	var slot *arena.SliceAddr[uint32]
	p1, p2, slot = getMutableField[arena.SliceAddr[uint32]](p1, p2)
	slice := slot.AssertValid()

	if isZC(slice) && slice.Cap() > 0 {

		p1, p2, slice = spillArena32(p1, p2, slice)
		p1.log(p2, "repeated fixed spill", "%v %v", slice.Addr(), slice)
	}

	if slice.Len() < slice.Cap() {
		slice = slice.SetLen(slice.Len() + 1)
		slice.Store(slice.Len()-1, v)
		p1.log(p2, "repeated fixed store", "%v %v", slice.Addr(), slice)

		*slot = slice.Addr()
		return p1, p2
	}

	slice = slice.AppendOne(p1.arena(), v)
	p1.log(p2, "repeated fixed append", "%v %v", slice.Addr(), slice)
	*slot = slice.Addr()
	return p1, p2
}

//go:nosplit
func appendFixed64(p1 parser1, p2 parser2, v uint64) (parser1, parser2) {
	_ = appendFixed[uint64]
	var slot *arena.SliceAddr[uint64]
	p1, p2, slot = getMutableField[arena.SliceAddr[uint64]](p1, p2)
	slice := slot.AssertValid()

	if isZC(slice) && slice.Cap() > 0 {

		p1, p2, slice = spillArena64(p1, p2, slice)
		p1.log(p2, "repeated fixed spill", "%v %v", slice.Addr(), slice)
	}

	if slice.Len() < slice.Cap() {
		slice = slice.SetLen(slice.Len() + 1)
		slice.Store(slice.Len()-1, v)
		p1.log(p2, "repeated fixed store", "%v %v", slice.Addr(), slice)

		*slot = slice.Addr()
		return p1, p2
	}

	slice = slice.AppendOne(p1.arena(), v)
	p1.log(p2, "repeated fixed append", "%v %v", slice.Addr(), slice)
	*slot = slice.Addr()
	return p1, p2
}

//go:nosplit
func parsePackedFixed32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parsePackedFixed[uint32]
	var zc zc
	p1, p2, zc = p1.bytes(p2)
	if zc.len() == 0 {
		return p1, p2
	}

	size, _ := unsafe2.Layout[uint32]()
	if zc.len()%size != 0 {
		p1.fail(p2, errCodeTruncated)
	}

	var slot *arena.SliceAddr[uint32]
	p1, p2, slot = getMutableField[arena.SliceAddr[uint32]](p1, p2)
	slice := slot.AssertValid()

	switch {
	case !isZC(slice):

	case slice.Cap() == 0:

		*slot = wrapZC[uint32](zc).Addr()
		goto exit
	default:

		p1, p2, slice = spillArena(p1, p2, slice)
	}

	{
		size, _ := unsafe2.Layout[uint32]()
		borrowed := unsafe2.Slice(
			unsafe2.Cast[uint32](unsafe2.Add(p1.c().src, zc.start())),
			zc.len()/size,
		)

		*slot = slice.Append(p1.arena(), borrowed...).Addr()
	}

exit:
	return p1, p2
}

//go:nosplit
func parsePackedFixed64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parsePackedFixed[uint64]
	var zc zc
	p1, p2, zc = p1.bytes(p2)
	if zc.len() == 0 {
		return p1, p2
	}

	size, _ := unsafe2.Layout[uint64]()
	if zc.len()%size != 0 {
		p1.fail(p2, errCodeTruncated)
	}

	var slot *arena.SliceAddr[uint64]
	p1, p2, slot = getMutableField[arena.SliceAddr[uint64]](p1, p2)
	slice := slot.AssertValid()

	switch {
	case !isZC(slice):

	case slice.Cap() == 0:

		*slot = wrapZC[uint64](zc).Addr()
		goto exit
	default:

		p1, p2, slice = spillArena(p1, p2, slice)
	}

	{
		size, _ := unsafe2.Layout[uint64]()
		borrowed := unsafe2.Slice(
			unsafe2.Cast[uint64](unsafe2.Add(p1.c().src, zc.start())),
			zc.len()/size,
		)

		*slot = slice.Append(p1.arena(), borrowed...).Addr()
	}

exit:
	return p1, p2
}

//go:nosplit
func parseVarint32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseVarint[uint32]
	p1, p2, p2.scratch = p1.varint(p2)
	p1, p2 = storeFromScratch[uint32](p1, p2)

	return p1, p2
}

//go:nosplit
func parseVarint64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseVarint[uint64]
	p1, p2, p2.scratch = p1.varint(p2)
	p1, p2 = storeFromScratch[uint64](p1, p2)

	return p1, p2
}

//go:nosplit
func parseZigZag32(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseZigZag[uint32]
	p1, p2, p2.scratch = p1.varint(p2)
	p2.scratch = uint64(zigzag64[uint32](p2.scratch))
	p1, p2 = storeFromScratch[uint32](p1, p2)

	return p1, p2
}

//go:nosplit
func parseZigZag64(p1 parser1, p2 parser2) (parser1, parser2) {
	_ = parseZigZag[uint64]
	p1, p2, p2.scratch = p1.varint(p2)
	p2.scratch = uint64(zigzag64[uint64](p2.scratch))
	p1, p2 = storeFromScratch[uint64](p1, p2)

	return p1, p2
}
